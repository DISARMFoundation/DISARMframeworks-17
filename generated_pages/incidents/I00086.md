# Incident I00086: #WeAreNotSafe – Exposing How a Post-October 7th Disinformation Network Operates on Israeli Social Media

* **Summary:** <I>“This report investigates a sophisticated and extensive coordinated network orchestrating a disinformation campaign targeting Israeli digital spaces since October 7th, 2023. By using digital forensic strategies and network analysis, this research unearths the magnitude of knowledge, organization, and resource expenditure of the campaign. Network analysis indicates the campaign includes thousands of accounts. Though unable to trace the exact origins, phone numbers belonging to accounts have been linked to Jordan and Egypt, and it is alleged that many of the tactics are likely inspired by previous Iranian campaigns. Advanced and novel tactics are unearthed in this report, including evading reverse image search, strategic hashtag use, and meticulous crafting of fake accounts and engagements. These tactics signify a nuanced approach to creating a disinformation network aimed at manipulating public opinion in Israel. This report also examines Meta’s responsibilities, highlighting concern over its inaction and staggered transparency. This report contributes crucial insights regarding influence campaigns in Israeli digital spaces and provides valuable learnings for social media platforms in combating disinformation campaign strategies and efforts.”</i>

* **incident type**: 

* **Year started:** 

* **Countries:**  , 

* **Found via:** 

* **Date added:** 


| Reference | Pub Date | Authors | Org | Archive |
| --------- | -------- | ------- | --- | ------- |
| [https://ict.org.il/post-0ctober-7th-disinformation-network-operates-on-israeli-social-media/](https://ict.org.il/post-0ctober-7th-disinformation-network-operates-on-israeli-social-media/) | 2024/02/21 | Uri Klempner | Reichman University | [https://web.archive.org/web/20240528220853/https://ict.org.il/post-0ctober-7th-disinformation-network-operates-on-israeli-social-media/](https://web.archive.org/web/20240528220853/https://ict.org.il/post-0ctober-7th-disinformation-network-operates-on-israeli-social-media/) |

 

| Technique | Description given for this incident |
| --------- | ------------------------- |
| [T0015 Create Hashtags and Search Artefacts](../../generated_pages/techniques/T0015.md) | In this report accounts were identified as part of “a sophisticated and extensive coordinated network orchestrating a disinformation campaign targeting Israeli digital spaces since October 7th, 2023”.<br><br> <i>“A core component of the detection methodology was applying qualitative linguistic analysis. This involved checking the fingerprint of language, syntax, and style used in the comments and profile of the suspected account. Each account bio consistently incorporated a combination of specific elements: emojis, nationality, location, educational institution or occupation, age, and a personal quote, sports team or band. The recurrence of this specific formula across multiple accounts hinted at a standardized template for bio construction.”</i><br><br> This example shows how actors can follow a templated formula to present a persona on social media platforms (T0143.002: Fabricated Persona, T0144.002: Persona Template). |
| [T0085.008 Machine Translated Text](../../generated_pages/techniques/T0085.008.md) | Accounts which were identified as part of “a sophisticated and extensive coordinated network orchestrating a disinformation campaign targeting Israeli digital spaces since October 7th, 2023” were presenting themselves as locals to Israel (T0097.101: Local Persona):<br><br><i>“Unlike usual low-effort fake accounts, these accounts meticulously mimic young Israelis. They stand out due to the extraordinary lengths taken to ensure their authenticity, from unique narratives to the content they produce to their seemingly authentic interactions.”<I> |
| [T0097.101 Local Persona](../../generated_pages/techniques/T0097.101.md) | <I>“[Meta] removed 41 Facebook accounts, five Groups, and four Instagram accounts for violating our policy against coordinated inauthentic behavior. This activity originated in Belarus and primarily targeted audiences in the Middle East and Europe.<br><br> “The core of this activity began in October 2021, with some accounts created as recently as mid-November. The people behind it used newly-created fake accounts — many of which were detected and disabled by our automated systems soon after creation — to pose as journalists and activists from the European Union, particularly Poland and Lithuania. Some of the accounts used profile photos likely generated using artificial intelligence techniques like generative adversarial networks (GAN). These fictitious personas posted criticism of Poland in English, Polish, and Kurdish, including pictures and videos about Polish border guards allegedly violating migrants’ rights, and compared Poland’s treatment of migrants against other countries’. They also posted to Groups focused on the welfare of migrants in Europe. A few accounts posted in Russian about relations between Belarus and the Baltic States.”</i><br><br> This example shows how accounts identified as participating in coordinated inauthentic behaviour were presenting themselves as journalists and activists while spreading operation narratives (T0097.102: Journalist Persona, T0097.103: Activist Persona).<br><br> Additionally, analysts at Meta identified accounts which were participating in coordinated inauthentic behaviour that had likely used AI-Generated images as their profile pictures (T0145.002: AI-Generated Account Imagery). |
| [T0143.002 Fabricated Persona](../../generated_pages/techniques/T0143.002.md) | <i>“[Meta] removed a network of accounts in Vietnam for violating our Inauthentic Behavior policy against mass reporting. They coordinated the targeting of activists and other people who publicly criticized the Vietnamese government and used false reports of various violations in an attempt to have these users removed from our platform. The people behind this activity relied primarily on authentic and duplicate accounts to submit hundreds — in some cases, thousands — of complaints against their targets through our abuse reporting flows.<br><br>“Many operators also maintained fake accounts — some of which were detected and disabled by our automated systems — to pose as their targets so they could then report the legitimate accounts as fake. They would frequently change the gender and name of their fake accounts to resemble the target individual. Among the most common claims in this misleading reporting activity were complaints of impersonation, and to a much lesser extent inauthenticity. The network also advertised abusive services in their bios and constantly evolved their tactics in an attempt to evade detection.“</i><br><br>In this example actors repurposed their accounts to impersonate targeted activists (T0097.103: Activist Persona, T0143.003: Impersonated Persona) in order to falsely report the activists’ legitimate accounts as impersonations (T0124.001: Report Non-Violative Opposing Content). |
| [T0144.002 Persona Template](../../generated_pages/techniques/T0144.002.md) | <i>“[Meta] removed a network of accounts in Vietnam for violating our Inauthentic Behavior policy against mass reporting. They coordinated the targeting of activists and other people who publicly criticized the Vietnamese government and used false reports of various violations in an attempt to have these users removed from our platform. The people behind this activity relied primarily on authentic and duplicate accounts to submit hundreds — in some cases, thousands — of complaints against their targets through our abuse reporting flows.<br><br>“Many operators also maintained fake accounts — some of which were detected and disabled by our automated systems — to pose as their targets so they could then report the legitimate accounts as fake. They would frequently change the gender and name of their fake accounts to resemble the target individual. Among the most common claims in this misleading reporting activity were complaints of impersonation, and to a much lesser extent inauthenticity. The network also advertised abusive services in their bios and constantly evolved their tactics in an attempt to evade detection.“</i><br><br>In this example actors repurposed their accounts to impersonate targeted activists (T0097.103: Activist Persona, T0143.003: Impersonated Persona) in order to falsely report the activists’ legitimate accounts as impersonations (T0124.001: Report Non-Violative Opposing Content). |
| [T0144.002 Persona Template](../../generated_pages/techniques/T0144.002.md) | <i>“[This article discusses a] longstanding network of bogus "think tanks" raise disinformation to a pseudoscience, and their studies' pull quotes and flashy stats become the "evidence" driving viral, fact-free stories<br><br> [...]<br><br> “[These inauthentic Think Tanks] tend toward hate: There's the white supremacist National Policy Institute and Jared Taylor's New Century Foundation; the anti-LGBTQ work of the Family Research Council and American College of Pediatricians; and a whole slew of groups fixated on immigration. Three of the biggest---Federation for American Immigration Reform, the Center for Immigration Studies, and NumbersUSA---are intertwined, all connected in their origins to white nationalist John Tanton.<br><br> “The Southern Poverty Law Center designates most of these organizations as bona fide hate groups. And yet most---FRC, CIS and FAIR in particular---enjoy relationships with some powerful politicians. Trump himself has met with leaders of the anti-immigration groups, hired people from FAIR and the Family Research Council, and cited the anti-immigration groups' erroneous figures.<br><br> “That's because phony think tanks are professional mimics, from the innocuous-sounding names---the Employment Policies Institute practically steals its name from the Economic Policy Institute---to their online presences. "It used to be you could trust a dot-edu or a dot-org," says Heidi Beirich, director of the Southern Poverty Law Center's Intelligence Project. "Now some of the main hate sites are dot-orgs.””</i><br><br> In this example an organisation designated as a hate group is presenting itself as a think tank (T0097.204: Think Tank Persona) in order to boost the perceived legitimacy of narratives. |
| [T0145.001 Copy Account Imagery](../../generated_pages/techniques/T0145.001.md) | <I>“[Russia’s social media] reach isn't the same as Russian state media, but they are trying to recreate what RT and Sputnik had done," said one EU official involved in tracking Russian disinformation. "It's a coordinated effort that goes beyond social media and involves specific websites."<br><br> “Central to that wider online playbook is a Telegram channel called Warfakes and an affiliated website. Since the beginning of the conflict, that social media channel has garnered more than 725,000 members and repeatedly shares alleged fact-checks aimed at debunking Ukrainian narratives, using language similar to Western-style fact-checking outlets.”</i><br><br> In this example a Telegram channel (T0151.004: Chat Platform, T0155.007: Encrypted Communication Channel) was established which presented itself as a source of fact checks (T0097.203: Fact Checking Organisation Persona). |
| [T0145.006 Attractive Person Account Imagery](../../generated_pages/techniques/T0145.006.md) | <I>“[Russia’s social media] reach isn't the same as Russian state media, but they are trying to recreate what RT and Sputnik had done," said one EU official involved in tracking Russian disinformation. "It's a coordinated effort that goes beyond social media and involves specific websites."<br><br> “Central to that wider online playbook is a Telegram channel called Warfakes and an affiliated website. Since the beginning of the conflict, that social media channel has garnered more than 725,000 members and repeatedly shares alleged fact-checks aimed at debunking Ukrainian narratives, using language similar to Western-style fact-checking outlets.”</i><br><br> In this example a Telegram channel (T0151.004: Chat Platform, T0155.007: Encrypted Communication Channel) was established which presented itself as a source of fact checks (T0097.203: Fact Checking Organisation Persona). |


DO NOT EDIT ABOVE THIS LINE - PLEASE ADD NOTES BELOW