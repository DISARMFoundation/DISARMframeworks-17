# Incident I00247: ‘It was extremely pornographic’: Cara Hunter on the deepfake video that nearly ended her political career

* **Summary:** <i>The Irish politician was targeted in 2022, in the final weeks of her run for office. She has never found out who made the malicious deepfake, but knew immediately she had to try to stop this happening to other women.</i>

* **incident type**: 

* **Year started:** 

* **Countries:**  , 

* **Found via:** 

* **Date added:** 


| Reference | Pub Date | Authors | Org | Archive |
| --------- | -------- | ------- | --- | ------- |
| [https://www.theguardian.com/society/ng-interactive/2025/dec/01/it-was-extremely-pornographic-cara-hunter-on-the-deepfake-video-that-nearly-ended-her-political-career](https://www.theguardian.com/society/ng-interactive/2025/dec/01/it-was-extremely-pornographic-cara-hunter-on-the-deepfake-video-that-nearly-ended-her-political-career) | 2025-12-01 00:00:00 | Anna Moore | The Guardian | [https://archive.is/2Y3VV](https://archive.is/2Y3VV) |

 

| Technique | Description given for this incident |
| --------- | ------------------------- |
| [T0039.001 Collaborating Assets Seed and Ping](../../generated_pages/techniques/T0039.001.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0039.002 Solicit Production of Fact Check](../../generated_pages/techniques/T0039.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0048.005 Voyeuristic Content](../../generated_pages/techniques/T0048.005.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0068 Respond to Breaking News Event or Active Crisis](../../generated_pages/techniques/T0068.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0068 Respond to Breaking News Event or Active Crisis](../../generated_pages/techniques/T0068.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0068 Respond to Breaking News Event or Active Crisis](../../generated_pages/techniques/T0068.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0068 Respond to Breaking News Event or Active Crisis](../../generated_pages/techniques/T0068.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0068 Respond to Breaking News Event or Active Crisis](../../generated_pages/techniques/T0068.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0068 Respond to Breaking News Event or Active Crisis](../../generated_pages/techniques/T0068.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0068 Respond to Breaking News Event or Active Crisis](../../generated_pages/techniques/T0068.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0068 Respond to Breaking News Event or Active Crisis](../../generated_pages/techniques/T0068.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0068 Respond to Breaking News Event or Active Crisis](../../generated_pages/techniques/T0068.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0085.004 Develop Document](../../generated_pages/techniques/T0085.004.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0086 Develop Image-Based Content](../../generated_pages/techniques/T0086.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0087 Develop Video-Based Content](../../generated_pages/techniques/T0087.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0087 Develop Video-Based Content](../../generated_pages/techniques/T0087.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0087 Develop Video-Based Content](../../generated_pages/techniques/T0087.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0087 Develop Video-Based Content](../../generated_pages/techniques/T0087.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0097.110 Party Official Persona](../../generated_pages/techniques/T0097.110.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0097.110 Party Official Persona](../../generated_pages/techniques/T0097.110.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0097.110 Party Official Persona](../../generated_pages/techniques/T0097.110.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0097.202 News Outlet Persona](../../generated_pages/techniques/T0097.202.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0120 Incentivize Sharing](../../generated_pages/techniques/T0120.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0120 Incentivize Sharing](../../generated_pages/techniques/T0120.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0146 Account Asset](../../generated_pages/techniques/T0146.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0146 Account Asset](../../generated_pages/techniques/T0146.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0146.003 Verified Account Asset](../../generated_pages/techniques/T0146.003.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0146.007 Automated Account Asset](../../generated_pages/techniques/T0146.007.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0149.004 Redirecting Domain Asset](../../generated_pages/techniques/T0149.004.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0151.001 Social Media Platform](../../generated_pages/techniques/T0151.001.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0152.004 Website Asset](../../generated_pages/techniques/T0152.004.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0152.004 Website Asset](../../generated_pages/techniques/T0152.004.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0153.004 QR Code Asset](../../generated_pages/techniques/T0153.004.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0160.002 Information is False](../../generated_pages/techniques/T0160.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0160.002 Information is False](../../generated_pages/techniques/T0160.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0160.002 Information is False](../../generated_pages/techniques/T0160.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0160.002 Information is False](../../generated_pages/techniques/T0160.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0160.002 Information is False](../../generated_pages/techniques/T0160.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0160.002 Information is False](../../generated_pages/techniques/T0160.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0160.002 Information is False](../../generated_pages/techniques/T0160.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0160.002 Information is False](../../generated_pages/techniques/T0160.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0160.002 Information is False](../../generated_pages/techniques/T0160.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0160.002 Information is False](../../generated_pages/techniques/T0160.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0160.002 Information is False](../../generated_pages/techniques/T0160.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0160.002 Information is False](../../generated_pages/techniques/T0160.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0160.002 Information is False](../../generated_pages/techniques/T0160.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0160.002 Information is False](../../generated_pages/techniques/T0160.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0160.002 Information is False](../../generated_pages/techniques/T0160.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0160.004 Information is Misleading](../../generated_pages/techniques/T0160.004.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0160.004 Information is Misleading](../../generated_pages/techniques/T0160.004.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0160.005 Content Produced as Satire](../../generated_pages/techniques/T0160.005.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0160.007 Claim Previously Fact Checked](../../generated_pages/techniques/T0160.007.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.001 Impersonated Content](../../generated_pages/techniques/T0161.001.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.001 Impersonated Content](../../generated_pages/techniques/T0161.001.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.002 Statement Incorrectly Presented as Made by Individual or Institution](../../generated_pages/techniques/T0161.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.002 Statement Incorrectly Presented as Made by Individual or Institution](../../generated_pages/techniques/T0161.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.002 Statement Incorrectly Presented as Made by Individual or Institution](../../generated_pages/techniques/T0161.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.002 Statement Incorrectly Presented as Made by Individual or Institution](../../generated_pages/techniques/T0161.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.002 Statement Incorrectly Presented as Made by Individual or Institution](../../generated_pages/techniques/T0161.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.002 Statement Incorrectly Presented as Made by Individual or Institution](../../generated_pages/techniques/T0161.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.002 Statement Incorrectly Presented as Made by Individual or Institution](../../generated_pages/techniques/T0161.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.002 Statement Incorrectly Presented as Made by Individual or Institution](../../generated_pages/techniques/T0161.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.002 Statement Incorrectly Presented as Made by Individual or Institution](../../generated_pages/techniques/T0161.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.002 Statement Incorrectly Presented as Made by Individual or Institution](../../generated_pages/techniques/T0161.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.002 Statement Incorrectly Presented as Made by Individual or Institution](../../generated_pages/techniques/T0161.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.002 Statement Incorrectly Presented as Made by Individual or Institution](../../generated_pages/techniques/T0161.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.002 Statement Incorrectly Presented as Made by Individual or Institution](../../generated_pages/techniques/T0161.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.002 Statement Incorrectly Presented as Made by Individual or Institution](../../generated_pages/techniques/T0161.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.002 Statement Incorrectly Presented as Made by Individual or Institution](../../generated_pages/techniques/T0161.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.002 Statement Incorrectly Presented as Made by Individual or Institution](../../generated_pages/techniques/T0161.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.002 Statement Incorrectly Presented as Made by Individual or Institution](../../generated_pages/techniques/T0161.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.002 Statement Incorrectly Presented as Made by Individual or Institution](../../generated_pages/techniques/T0161.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.003 Falsified Graffiti or Signage](../../generated_pages/techniques/T0161.003.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0161.004 Imagery Depicting Individual Edited to Introduce Sexual Material](../../generated_pages/techniques/T0161.004.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162 Reframe Context](../../generated_pages/techniques/T0162.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162 Reframe Context](../../generated_pages/techniques/T0162.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162 Reframe Context](../../generated_pages/techniques/T0162.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.001 Incorrect Subtitled Speech Reframes Context](../../generated_pages/techniques/T0162.001.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.002 Edits Made to News Report which Reframe Context](../../generated_pages/techniques/T0162.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.003 Historic Content Incorrectly Presented as Current](../../generated_pages/techniques/T0162.003.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.003 Historic Content Incorrectly Presented as Current](../../generated_pages/techniques/T0162.003.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.003 Historic Content Incorrectly Presented as Current](../../generated_pages/techniques/T0162.003.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.003 Historic Content Incorrectly Presented as Current](../../generated_pages/techniques/T0162.003.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.003 Historic Content Incorrectly Presented as Current](../../generated_pages/techniques/T0162.003.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.003 Historic Content Incorrectly Presented as Current](../../generated_pages/techniques/T0162.003.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.003 Historic Content Incorrectly Presented as Current](../../generated_pages/techniques/T0162.003.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.004 Content Incorrectly Presented as Depicting Another Location](../../generated_pages/techniques/T0162.004.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.004 Content Incorrectly Presented as Depicting Another Location](../../generated_pages/techniques/T0162.004.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.005 Video Game Content Incorrectly Presented as Depicting Reality](../../generated_pages/techniques/T0162.005.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.005 Video Game Content Incorrectly Presented as Depicting Reality](../../generated_pages/techniques/T0162.005.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.005 Video Game Content Incorrectly Presented as Depicting Reality](../../generated_pages/techniques/T0162.005.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.005 Video Game Content Incorrectly Presented as Depicting Reality](../../generated_pages/techniques/T0162.005.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.005 Video Game Content Incorrectly Presented as Depicting Reality](../../generated_pages/techniques/T0162.005.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.005 Video Game Content Incorrectly Presented as Depicting Reality](../../generated_pages/techniques/T0162.005.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.008 Context Reframed by Edits to Media](../../generated_pages/techniques/T0162.008.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.008 Context Reframed by Edits to Media](../../generated_pages/techniques/T0162.008.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.008 Context Reframed by Edits to Media](../../generated_pages/techniques/T0162.008.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.010 Entertainment Media Content Incorrectly Presented as Depicting Reality](../../generated_pages/techniques/T0162.010.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.010 Entertainment Media Content Incorrectly Presented as Depicting Reality](../../generated_pages/techniques/T0162.010.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.010 Entertainment Media Content Incorrectly Presented as Depicting Reality](../../generated_pages/techniques/T0162.010.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0162.011 Content Originally Produced as Satire Presented as Not Satire](../../generated_pages/techniques/T0162.011.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0163.001 Narrative Cites Nonexistent Academic Research](../../generated_pages/techniques/T0163.001.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0163.002 Narrative Misrepresents Findings of Cited Academic Research](../../generated_pages/techniques/T0163.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0163.002 Narrative Misrepresents Findings of Cited Academic Research](../../generated_pages/techniques/T0163.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0163.002 Narrative Misrepresents Findings of Cited Academic Research](../../generated_pages/techniques/T0163.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0163.003 Narrative Cites Retracted Academic Research](../../generated_pages/techniques/T0163.003.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0163.003 Narrative Cites Retracted Academic Research](../../generated_pages/techniques/T0163.003.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0163.004 Narrative Cites Academic Research not Peer Reviewed](../../generated_pages/techniques/T0163.004.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0163.004 Narrative Cites Academic Research not Peer Reviewed](../../generated_pages/techniques/T0163.004.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0164.002 Narrative Uses Selective Statistics to Support Claim](../../generated_pages/techniques/T0164.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0164.003 Narrative Uses Misinterpreted Statistics to Support Claim](../../generated_pages/techniques/T0164.003.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0164.003 Narrative Uses Misinterpreted Statistics to Support Claim](../../generated_pages/techniques/T0164.003.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0164.003 Narrative Uses Misinterpreted Statistics to Support Claim](../../generated_pages/techniques/T0164.003.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0165 Edited Content](../../generated_pages/techniques/T0165.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0165 Edited Content](../../generated_pages/techniques/T0165.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0165 Edited Content](../../generated_pages/techniques/T0165.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0165.003 Playback Speed Altered](../../generated_pages/techniques/T0165.003.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0166 AI-Generated Content](../../generated_pages/techniques/T0166.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0166 AI-Generated Content](../../generated_pages/techniques/T0166.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0166 AI-Generated Content](../../generated_pages/techniques/T0166.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0166 AI-Generated Content](../../generated_pages/techniques/T0166.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0166.001 Deepfake Impersonation](../../generated_pages/techniques/T0166.001.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0166.002 Sexual Deepfake Impersonation](../../generated_pages/techniques/T0166.002.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0166.003 AI-Nudified Imagery](../../generated_pages/techniques/T0166.003.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0167.001 Use of Clickbait](../../generated_pages/techniques/T0167.001.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0167.001 Use of Clickbait](../../generated_pages/techniques/T0167.001.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0167.001 Use of Clickbait](../../generated_pages/techniques/T0167.001.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |
| [T0167.001 Use of Clickbait](../../generated_pages/techniques/T0167.001.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |


DO NOT EDIT ABOVE THIS LINE - PLEASE ADD NOTES BELOW