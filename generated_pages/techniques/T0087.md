# Technique T0087: Develop Video-Based Content

**Summary**: Creating and editing false or misleading video artefacts, often aligned with one or more specific narratives, for use in a disinformation campaign. This may include staging videos of purportedly real situations, repurposing existing video artefacts, or using AI-generated video creation and editing technologies (including deepfakes).

**Tactic**: TA06 Develop Content 


| Associated Technique | Description |
| --------- | ------------------------- |



| Incident | Descriptions given for this incident |
| -------- | -------------------- |
| [I00110 How COVID-19 conspiracists and extremists use crowdfunding platforms to fund their activities](../../generated_pages/incidents/I00110.md) | <i>As families desperately seek to find missing loved ones and communities grapple with immeasurable losses of both life and property in the wake of [2024’s] Hurricane Helene, AI slop scammers appear to be capitalizing on the moment for personal gain.<br><br>A Facebook account called "Coastal Views" usually shares calmer AI imagery of nature-filled beachside scenes. The account's banner image showcases a signpost reading "OBX Live," OBX being shorthand for North Carolina's Outer Banks islands.<br><br>But starting this weekend, the account shifted its approach dramatically, as first flagged by a social media user on X.<br><br>Instead of posting "photos" of leaping dolphins and sandy beaches, the account suddenly started publishing images of flooded mountain neighborhoods, submerged houses, and dogs sitting on top of roofs.<br><br>But instead of spreading vital information to those affected by the natural disaster, or at the very least sharing real photos of the destruction, the account is seemingly trying to use AI to cash in on all the attention the hurricane has been getting.<br><br>The account links to an Etsy page for a business called" OuterBanks2023," where somebody who goes by "Alexandr" sells AI-generated prints of horses touching snouts with sea turtles, Santa running down the shoreline with a reindeer, and sunsets over ocean waves.</i><br><br>A Facebook page which presented itself as being associated with North Carolina which posted AI generated images changed to posting AI generated images of hurricane damage after Hurricane Helene hit North Carolina (T0151.003: Online Community Page, T0151.001: Social Media Platform, T0115: Post Content, T0086.002: Develop AI-Generated Images (Deepfakes), T0068: Respond to Breaking News Event or Active Crisis). <br><br>The account included links (T0122: Direct Users to Alternative Platforms) to an account on Etsy, which sold prints of AI generated images (T0146: Account Asset, T0148.007: eCommerce Platform). |
| [I00111 Patreon Is Bankrolling Climate Change Deniers While We All Burn](../../generated_pages/incidents/I00111.md) | <i>The Moscow firm Social Design Agency (SDA) has been attributed as being behind a Russian disinformation project known as Doppelganger:<br><br>The SDA’s deception work first surfaced in 2022, likely almost immediately after Doppelganger got off the ground. In April of that year, Meta, the parent company of Facebook and Instagram, disclosed in a quarterly report that it had removed from its platforms “a network of about 200 accounts operated from Russia.” By August 2022, German investigative journalists revealed that they had discovered forgeries of about 30 news sites, including many of the country’s biggest media outlets—Frankfurter Allgemeine, Der Spiegel, and Bild—but also Britain’s Daily Mail and France’s 20 Minutes. The sites had deceptive URLs such as www-dailymail-co-uk.dailymail.top. </i><br><br>As part of the SDA’s work, they created many websites which impersonated existing media outlets. Sites used domain impersonation tactics to increase perceived legitimacy of their impersonations (T0097.202: News Outlet Persona, T0143.003: Impersonated Persona, T0152.003: Website Hosting Platform, T0149.003: Lookalike Domain). |
| [I00125 The Agency](../../generated_pages/incidents/I00125.md) | Discord is an example of a T0151.004: Chat Platform, which allows users to create their own T0151.005: Chat Community Server. The Institute for Strategic Dialog (ISD) conducted an investigation into the extreme right’s usage of Discord servers:<br><br><i>Discord is a free service accessible via phones and computers. It allows users to talk to each other in real time via voice, text or video chat and emerged in 2015 as a platform designed to assist gamers in communicating with each other while playing video games. The popularity of the platform has surged in recent years, and it is currently estimated to have 140 million monthly active users.<br><br>Chatrooms – known as servers - in the platform can be created by anyone, and they are used for a range of purposes that extend far beyond gaming. Such purposes include the discussion of extreme right-wing ideologies and the planning of offline extremist activity. Ahead of the far-right Unite the Right rally in Charlottesville, Virginia, in August 2017, organisers used Discord to plan and promote events and posted swastikas and praised Hitler in chat rooms with names like “National Socialist Army” and “Führer’s Gas Chamber”.</i><br><br>In this example a Discord server was used to organise the 2017 Charlottesville Unite the Right rally. Chat rooms such in the server were used to discuss different topics related to the rally (T0057: Organise Events, T0126.002: Facilitate Logistics or Support for Attendance, T0151.004: Chat Platform, T0151.005: Chat Community Server, T0151.006: Chat Room).<br><br><i>Another primary activity engaged in the servers analysed are raids against other servers associated with political opponents, and in particular those that appear to be pro-LGBTQ. Raids are a phenomenon in which a small group of users will join a Discord server with the sole purpose of spamming the host with offensive or incendiary messages and content with the aim of upsetting local users or having the host server banned by Discord. On two servers examined here, raiding was their primary function.<br><br>Among servers devoted to this activity, specific channels were often created to host links to servers that users were then encouraged to raid. Users are encouraged to be as offensive as possible with the aim of upsetting or angering users on the raided server, and channels often had content banks of offensive memes and content to be shared on raided servers.<br><br>The use of raids demonstrates the gamified nature of extremist activity on Discord, where use of the platform and harassment of political opponents is itself turned into a type of real-life video game designed to strengthen in-group affiliation. This combined with the broader extremist activity identified in these channels suggests that the combative activity of raiding could provide a pathway for younger people to become more engaged with extremist activity.</i><br><br>Discord servers were used by members of the extreme right to coordinate harassment of targeted communities (T0048: Harass, T0049.005: Conduct Swarming, T0151.004: Chat Platform, T0151.005: Chat Community Server). |
| [I00217 False Authority: How the BBC Became a Favorite Brand for Fake Video Creators](../../generated_pages/incidents/I00217.md) | <i>[Translated from original in Russian] The mass production of fake videos featuring the logos of prominent international media outlets is one of the hallmarks of Russia's information war against Ukraine. Since the start of the full-scale invasion, creators of such fakes have released dozens of videos imitating the designs of Al Jazeera , Euronews , Deutsche Welle , Reuters , Fox News , and other major foreign media outlets  (T0087: Develop Video-Based Content, T0161.001: Impersonated Content, T0097.202: News Outlet Persona). But the British Broadcasting Corporation is a particular favorite among disinformationists. "Verified" explains how the BBC's disinformation videos are made, what they cover, and how to distinguish genuine content from fake.<br><br>What the fake videos say<br><br>At first glance, the videos purporting to be BBC reports focus on events unfolding in various countries around the world (T0068: Respond to Breaking News Event or Active Crisis), but all of them portray Ukraine and Western countries in a negative light. "Verified" is aware of nine such recordings, but there could have been more: some may have failed to resonate and escaped the attention of fact-checkers. <br><br>The most recent of these videos appeared in mid-December 2023. It reported that over 10,000 cameras had been discovered in Ukraine, the data from which had been transmitted to Russia and stored on Russian servers since 2004. Although this video is not available on the BBC's website or official social media accounts, it is based on a genuine journalistic investigation published several days earlier by the " Schemes " project. Its authors discovered that TRASSIR cameras were supplied to Ukraine, the data from which was transmitted through Russian servers and could potentially be accessed by the FSB.<br><br>This is the only case known to "Verified" where a fake BBC video was based on credible information (T0087: Develop Video-Based Content, T0161.001: Impersonated Content, T0097.202: News Outlet Persona, T0160.001: Information is Verified). The video likely served only a supporting role—it was distributed alongside a fake screenshot of a news story from the British Broadcasting Corporation (T0087: Develop Video-Based Content, T0161.001: Impersonated Content, T0097.202: News Outlet Persona), which quoted US Congressman Matt Gaetz as saying, "For two years, we supported a country that didn't even bother to get rid of Russian cameras in its capital. The question remains, who is dumber: us or the Ukrainians?" Gaetz has consistently opposed further American aid to Kyiv, and his statements on this topic are regularly quoted by Russian state media.<br><br>Another video released in December claimed that Bellingcat investigators had information about Ukraine selling weapons to the terrorist group Hamas, which attacked Israel on October 7. David Arakhamia, chairman of the Servant of the People faction in the Verkhovna Rada, was accused of organizing the deal, and the information was allegedly confirmed by BBC Verify journalist Shayan Sardarizade and Bellingcat founder Eliot Higgins. According to TGStat data, this video (which Reuters fact-checkers found to be fabricated (T0087: Develop Video-Based Content, T0161.001: Impersonated Content, T0097.202: News Outlet Persona)) has been viewed over 1 million times in the Russian-language segment of Telegram alone. <br><br>Similar claims (also citing Bellingcat) were present in a video analyzed by "Verified" in October 2023. At the time, the Ukrainian Ministry of Defense was accused of selling weapons to militants. The video, which garnered roughly the same number of views as the later one, featured the BBC logo and intro, as well as other distinctive design elements, but this video also turned out to be fake (T0087: Develop Video-Based Content, T0161.001: Impersonated Content, T0097.202: News Outlet Persona).<br><br>A third report based on Bellingcat's "findings," allegedly produced by the BBC, circulated in late November. The video, citing the investigative group, claimed that former adviser to the Ukrainian Presidential Office Oleksiy Arestovych spent $500,000 on private jets over six months. Bellingcat founder Eliot Higgins denied conducting such an investigation. The video also appears to be missing from the BBC's website (T0087: Develop Video-Based Content, T0161.001: Impersonated Content, T0097.202: News Outlet Persona).<br><br>In early October 2023, a video disguised as a BBC story featuring a prediction by essayist Nassim Taleb circulated. Taleb allegedly claimed that the United States was planning to leave NATO and stop aiding Ukraine. The video, which had garnered several hundred thousand views on Telegram, was nowhere to be found on the British media corporation's website or social media accounts (T0087: Develop Video-Based Content, T0161.001: Impersonated Content, T0097.202: News Outlet Persona), and the writer himself denied ever making such a statement (T0161.002: Statement Incorrectly Presented as Made by Individual or Institution). <br><br>On August 30, fact-checkers at Logically Facts published an analysis of yet another video released on behalf of the BBC, which claimed that Yevgeny Prigozhin did not die in the plane crash in the Tver region, but that his death was allegedly staged by the Kremlin with the consent of the head of the Wagner PMC. The video became popular not only among Russian-speaking internet users (over 3 million views on Telegram) but also in the English-speaking segment (for example, one of the posts on X was viewed over 380,000 times). As in other cases, the video turned out to be a fake, and the BBC had no connection with it (T0087: Develop Video-Based Content, T0161.001: Impersonated Content, T0097.202: News Outlet Persona).<br><br>The videos described above were edited vertically, but some fake videos were also disguised as more familiar horizontal footage. For example, in early August 2023, a video circulated claiming that "Britain is suffering from sanctions" imposed by London on Russia due to its aggression against Ukraine. However, by changing the video's format, its creators stumbled—the BBC does not use such a format for such videos (T0087: Develop Video-Based Content, T0161.001: Impersonated Content, T0097.202: News Outlet Persona). The viral video, which consists of a montage of photos and reports unrelated to the topic of sanctions, is not available on the broadcaster's website or social media. The experiment was relatively unsuccessful—the fake story failed to generate much interest in either English or Russian. <br><br>In May 2022, a video widely circulated on social media X , purporting to show BBC journalists showing an order to send Polish troops to Ukraine (T0087: Develop Video-Based Content, T0161.001: Impersonated Content, T0097.202: News Outlet Persona). Fact-checkers from the Polish project Demagog discovered that the document was falsified (T0085.004: Develop Document, T0161.001: Impersonated Content, T0097.206: Government Institution Persona), while their colleagues at Reuters analyzed the video, which mimicked the BBC design, and came to a similar conclusion. In Russian, the image of the order gained more popularity , while in English, the fake footage gained more popularity. <br><br>In April 2022, a video of a missile strike on a train station in Kramatorsk , killing 61 civilians , went viral . The video, purportedly released by the BBC, blamed Ukraine for the attack (T0087: Develop Video-Based Content, T0161.001: Impersonated Content, T0097.202: News Outlet Persona). The subtitles stated that Russia does not use Tochka-U missiles, and the serial number on a shell fragment found at the site of the tragedy indicated that the missile belonged to Ukraine. <br><br>This “BBC story” was broadcast on Russian state television channels (in particular, on “Russia 24”), and also formed the basis for numerous publications in the Russian media .<br><br>Last spring, journalists, fact-checkers, and media researchers first noticed the emergence of several fabricated stories about the war in Ukraine, disseminated under the branding of the BBC and other well-known media outlets. BBC correspondent Joe Inwood wrote on his X account (then Twitter): "...Someone appears to have obtained BBC video tools and created a convincing, but fake, video." <br><br>The fake videos described above were designed identically, using the BBC News banner, the British television channel's logo, and a consistent design code. The vast majority of these videos are vertical and mimic the style of BBC social media posts. The fake videos are primarily edited together from video fragments available in the public domain or produced by other media outlets (T0165: Edited Content, T0084.002: Plagiarise Content), accompanied by subtitles and background music. Similarly, as noted above, over the past year and a half, videos have been faked and attributed to media outlets around the world.<br><br>Along with the fake videos, equally fake screenshots of publications on the websites of various foreign media outlets, including the BBC , were also distributed (T0086: Develop Image-Based Content, T0161.001: Impersonated Content, T0097.202: News Outlet Persona). Sometimes, they even became elements of disinformation videos. For example, a screenshot of a non-existent BBC news story was featured in a video purportedly from Reuters, which reported on appeals from boxer Mike Tyson and actor Elijah Wood to Ukrainian President Volodymyr Zelenskyy (the Western stars allegedly asked the politician to begin drug addiction treatment (T0161.002: Statement Incorrectly Presented as Made by Individual or Institution)).<br><br>Fake reports attributed to the BBC have appeared before, but they were far fewer in number, presented differently, and, in most cases, apparently were not created with the intention of disinformation. For example , in 2018, a video about an imminent nuclear war between NATO and Russia went viral (T0087: Develop Video-Based Content, T0161.001: Impersonated Content, T0097.202: News Outlet Persona) ( a second wave of distribution occurred in January 2022 (T0160.006: Content Previously Fact Checked)). The video purported to be a clip from a BBC television broadcast, but it turned out that the recording was created independently of the British broadcaster and "purely for entertainment purposes." Neither "Verified" nor other fact-checking projects were able to find any similar disclaimers for more recent videos.<br><br>There's no trace of any of the videos described above, which appeared in 2022–2023, on the BBC website or on the corporation's social media accounts, and the media group's official representatives have repeatedly been forced to claim that the stories are fabricated. These claims are independently confirmed by fact-checking projects operating in various countries. However, by this point, the fake publications have accumulated millions of views and influenced the opinions of many people about the global situation. <br><br>Who is behind the falsifications?<br><br>Many of the videos described above began spreading on social media shortly after the publication of statements by Russian officials and speakers collaborating with state media containing the same points (T0068: Respond to Breaking News Event or Active Crisis). For example, the narrative about Ukrainian weapons in the hands of Hamas militants emerged on October 7, the day of the group's attack on Israel. This was reported in a commentary to Argumenty i Fakty , without citing a source, by orientalist Yevgeny Satanovsky, until recently a regular guest on TV host Vladimir Solovyov's broadcasts. On October 9, Deputy Chairman of the Russian Security Council Dmitry Medvedev made the same statement on his Telegram channel , and the very next day, a fake video about a non-existent Bellingcat investigation began circulating in the Russian-language segment of Telegram (T0087: Develop Video-Based Content, T0068: Respond to Breaking News Event or Active Crisis, T0161.001: Impersonated Content, T0097.202: News Outlet Persona). The report that the attack on the Kramatorsk train station was carried out by Ukrainian troops, not Russian ones, was widely disseminated in Russia by federal media on the day of the attack, April 8, 2022. Soon, a video with the BBC logo, repeating the official Russian narrative, appeared on social media (T0087: Develop Video-Based Content, T0068: Respond to Breaking News Event or Active Crisis, T0161.001: Impersonated Content, T0097.202: News Outlet Persona). <br><br>[...]<br><br>Almost all the videos examined by "Verified" and other fact-checkers mimic the design of the videos the BBC uses on its X social media account and sometimes on Instagram , making them difficult to immediately distinguish from the real thing. However, sometimes it's enough to simply visit the website or the official BBC News accounts on X , Instagram , YouTube , or TikTok to confirm that such information has not been published there.<br><br>There are also a number of significant differences in the design of fake and real videos, which make it possible to determine whether a video is fabricated or not, even without specialized tools or video content verification skills. <br><br>Firstly, the fake videos feature background music, while the originals rarely use it (if music is present, it's overlaid on the main audio track). The so-called caption videos (videos with embedded subtitles) published by the BBC use the original audio from the footage used in the videos , while the fake videos, on the contrary, lack it.<br><br>Secondly, when a genuine BBC report shows a clip of someone speaking, their voice is not muted. For example, in the fabricated December video about Ukraine selling arms to Hamas, the footage of Eliot Higgins and Shayan Sardarizadeh allegedly making this statement is accompanied only by background music, and the British journalist's lip movements make it clear that he is speaking a completely different phrase than the one in the caption. Footage of Nassim Taleb was used in exactly the same way in a report about the impending US withdrawal from NATO. <br><br>Thirdly, although the disinformation campaigners use elements of the BBC video design (the opening title, the logo, the characteristic vertical red stripe near the title), the font in the fake videos does not match the company's.<br><br>Fourth, native speakers may note that the captions of such fake videos regularly contain spelling, grammar, and stylistic errors that are virtually impossible to find in a reputable media corporation. For example, an October video about a Bellingcat investigation includes the phrase "Ukrainian Defense Prime Minister," while the captions of a video about Nassim Taleb's forecast sometimes lack the necessary articles.<br><br>These recommendations apply to any videos of this kind, regardless of whose logo you see in the frame. And they're worth taking on board, as there's no reason to believe that the current method of fake news stories, which generates millions of views, will become tiresome for disinformation makers anytime soon.</i> |
| [I00218 BBC News video claiming Prigozhin death was staged is a fake](../../generated_pages/incidents/I00218.md) | <i>Context<br><br> <br><br>An alleged BBC News social media video containing claims that the Kremlin staged the death of Yevgeny Prigozhin and that the Wagner leader is still alive is circulating on social media. "BBC is going full conspiracy theory 'It was all staged - Prigozhin is alive,'" reads one post containing the video, uploaded to X (formerly Twitter) on August 29, 2023, that has amassed 335,000 views.  <br><br>The video is edited in the style of videos uploaded to the BBC's social media channels, using the BBC News logo. However, the video is a fake . The BBC has not reported that Prigozhin's death was staged or that he is still alive. On the contrary, the BBC has cited Russian authorities sources that Prigozhin died in a plane crash on August 23, 2023, and have reported from the cemetery where he is believed to have been buried on August 29  (T0087: Develop Video-Based Content, T0068: Respond to Breaking News Event or Active Crisis, T0161.001: Impersonated Content, T0097.202: News Outlet Persona). <br><br>In fact<br><br>BBC Verify journalist Shayan Sardarizadeh debunked the video on X (formerly Twitter). "A fake video with the logo and branding of BBC News is being shared online, claiming that Wagner chief Yevgeny Prigozhin's death was staged by the Kremlin. The video is completely fake. BBC News has never published such a video," wrote Sardarizadeh in a post. <br><br>A BBC spokesperson told Logically Facts: "We are aware of this fake video, and our lawyers are urgently looking into it. In a world of increasing disinformation, we urge everyone to check links and URLs to ensure they are getting news from a trusted source."<br><br>[...]<br><br>The verdict<br><br>A fake video using the BBC's logo and style claims that Yevgeny Prigozhin's death was staged by the Kremlin. The video has never been available on BBC media channels and has been debunked by a BBC journalist. No reporting corresponding with the video can be found on BBC's website. Therefore, we have marked the video as fake.</i> |
| [I00220 Fact Check: Fake BBC clip on Ukrainian politician selling arms to Hamas](../../generated_pages/incidents/I00220.md) | <i>The BBC did not publish a video claiming that a Ukrainian politician sold arms to Hamas as suggested by images circulating online that carry BBC branding (T0087: Develop Video-Based Content, T0161.001: Impersonated Content, T0097.202: News Outlet Persona) and cite investigative group Bellingcat (T0161.002: Statement Incorrectly Presented as Made by Individual or Institution). The clip is fake, according to representatives of both BBC and Bellingcat.<br><br>The clip as well as screengrabs from the video, which surfaced on X and Facebook, have the appearance of a BBC social media video, with the BBC logo visible at the top left corner.<br><br>Text overlaid on the video at the start of the clip reads: “A Ukrainian politician may be involved in arms sales to Hamas.”<br><br>Further text cites Bellingcat as having reported that the International Criminal Court is “preparing a case” against David Arakhamia, the leader of Ukraine’s Servant of the People political party, although the video caption incorrectly spells his name.<br><br>The video (timestamp 00:48s) cites BBC journalist Shayan Sardarizadeh as saying: “We are dealing with serious allegations.”<br><br>Sardarizadeh said on X that the quote attributed to him is “fake” and “total nonsense.” (T0161.002: Statement Incorrectly Presented as Made by Individual or Institution)<br><br>A BBC spokesperson told Reuters in a Dec. 6 email, “This is not a BBC News video.”<br><br>Founder of Bellingcat, Eliot Higgins also said in an email that Bellingcat "has done no investigation that supports the claims in the videos.” (T0161.002: Statement Incorrectly Presented as Made by Individual or Institution)<br><br>[...]<br><br>BBC News did not publish the video, a spokesperson said to Reuters. Bellingcat did not release any related report, the founder of the organization said.</i> |
| [I00247 ‘It was extremely pornographic’: Cara Hunter on the deepfake video that nearly ended her political career](../../generated_pages/incidents/I00247.md) | <i>When Cara Hunter, the Stormont politician, looks back on the moment she found out she had been deepfaked, she says it is “like watching a horror movie”. The setting is her grandmother’s rural home in the west of Tyrone on her 90th birthday, April 2022. “Everyone was there,” she says. “I was sitting with all my closest family members and family friends when I got a notification through Facebook Messenger.” It was from a stranger. “Is that you in the video … the one going round on WhatsApp?” he asked.<br><br>Hunter made videos all the time, especially then, less than three weeks before elections for the Northern Ireland assembly. She was defending her East Londonderry seat, campaigning, canvassing, debating. Yet, as a woman, this message from a man she didn’t know was enough to put her on alert. “I replied that I wasn’t sure which video he was talking about,” Hunter says. “So he asked, did I want to see it?” Then he sent it over.<br><br>“It was extremely pornographic,” she says. “I won’t go into detail but I want you to understand what I had to compute. Even as I’m sitting here talking about it now, I suddenly feel roasting hot. It’s a clip of a blue-walled bedroom, and it has American plugs. There’s this woman – a woman who seemed to have my face – who is doing a handstand and having mutual oral sex with a man. And I’m looking at this, sitting surrounded by family, in the middle of a very heated election campaign.” (T0087: Develop Video-Based Content, T0166.002: Sexual Deepfake Impersonation, T0097.110: Party Official Persona, T0068: Respond to Breaking News Event or Active Crisis) At the same time, Hunter’s phone was blowing up with message after message from strangers who had seen the video. “All of them were just really vitriolic,” she says. “Those messages were from people who hate women.” (T0048: Harass)<br><br>It’s hard to fathom how unknown and “niche” deepfake pornography still was when this happened, only three years ago. “The only ‘altered images’ I really knew about at that time were Snapchat filters,” says Hunter. “My initial reaction was: ‘Is this a woman who looks similar to me?’ Then a friend asked if this could be one of those things where they put your face on to someone else’s body. We were Googling it, trying to see what it was called.” Since that time, this tech has come a frighteningly long way. “Now I have girls calling me, telling me this has happened to them and ruined their lives. Just recently, one young woman told me it had happened to her and 14 others, all when they were under 18,” she says. “Teachers tell me that they’ve seen a spike in nudification apps in schools (T0166.003: AI-Nudified Imagery). The affordability and accessibility has increased tenfold.”<br><br>In England and Wales, legislation is finally grappling with the issue – the Online Safety Act and the Data (Use and Access) Act 2025 have made the sharing, creation and requesting of deepfake intimate image abuse illegal. In Northern Ireland, too, there are plans to criminalise it – the consultation process closed in October.<br><br>Yet it seems the public has been slow to grasp its harms. New police research, released last week, suggests one in four people still think there is nothing wrong with creating and sharing sexual deepfakes, or feel neutral about it. “I was shocked by that,” says Hunter. “This is a world where falsified, highly sexualised images can ruin your life, ruin your relationships, your reputation and career, and there are people who think: ‘It’s a bit of fun, it’s a bit of craic.’” She takes a long sigh. “I was shocked – but at the same time, not surprised. The normalisation of violence against women and girls cannot be overstated.”<br><br>For Hunter, who has just turned 30, the weeks after the video’s release were “horrific”. “I didn’t know what to do. Should I do a press release? Should I put a Facebook status out? You’re a young woman, 27 years old, and it was so hard to be taken seriously politically anyway.” Her party, the Social Democratic and Labour party (SDLP), advised her to ignore it. “Even recalling it now, I can’t believe this happened, but they said: ‘We’re two and a half weeks from an election. If you do a press release, your name will be right up there with words like ‘pornography’ – and people will see you through a sexual lens and also go looking for it.’ They said: ‘If 10,000 people know about that video now, 100,000 will know after you’ve drawn attention to it.’ Those numbers are burnt into my brain.”<br><br>Hunter then turned to the police, who informed her (apologetically) that no crime had been committed, and they didn’t have the technology or expertise to investigate anyway. It was Hunter who found the original video, with the original woman’s face, by using screenshots from it in reverse image search engines. When it came to identifying who had released the deepfake video on WhatsApp, she learned it was an encrypted platform whose users had the right to privacy. “I’d like to think I have a right for my life not to be ruined,” she says. “You’re one person up against the massive system of tech and coding.”<br><br>Many memories from that period still feel mortifying. Hunter’s uncle hammering at the door, having been shown the video by his friend. She had to invite him in, sit him down and explain that it wasn’t real. Then later, she had to explain it all again to her father.<br><br>“Everywhere I went, people I used to speak to would cross the road to avoid me,” she says. “I live in a beautiful coastal town that I’m lucky to represent. A mile from my house is a bar and, a couple of days after this happened, there was a party for a staff member’s birthday. I thought: ‘I can’t let it consume me. I’m going to go there and have a drink.’ On the way, a man approached me and asked me for oral sex. I kept going, reached the bar and there was complete silence when I walked in. I realised it was a mistake.”<br><br>Despite Hunter’s fear that silence would be viewed as evidence that the video was genuine, she followed the party’s advice and attempted to campaign as normal. “I remember saying to my boyfriend, who is now my husband: ‘I don’t care if I’m elected or not. I just want this to be over.’” As it turned out, Hunter won by just 14 votes – making her seat the most marginal in Northern Ireland.<br><br>[...]<br><br>She fears experiences like hers will deter young women from entering politics (T0139.003: Deter). “I have these very capable young girls on work experience in my office and I don’t want them to think this is part and parcel of the political experience,” she says. “Any time I ask a woman to consider standing, I have to ask three or four times. With men, nine out of 10 times, they’ll say yes straight away.”<br><br>There’s little doubt that the deepfake of Hunter directly affected the democratic process. How could it not have lost her votes? (T0139.001: Discourage) Women have been the first victims of this technology – a 2023 study found that 98% of online deepfakes are pornographic and that 99% of the targets are women. However, in this era Hunter terms “the AI Olympics”, the potential for future harms goes far beyond this. The deepfake of Joe Biden’s voice urging voters not to vote in the New Hampshire primary, or the video of Volodymyr Zelenskyy telling his troops to surrender are early examples. While the UK government has begun to tackle deepfake pornography, Danish authorities are attempting to go much further by changing copyright law. The proposed changes guarantee everyone’s right to their own body, facial features and voice. (Though the law would allow expressions of satire and parody.) “If we could bring that in here, I’d say ‘Hallelujah!’” says Hunter. “What we could also do – and what I’d really like to see – is a mandatory marking which shows on every AI video so everyone understands what they’re seeing.”<br><br>Beyond politics, Hunter still thinks about that video clip, that blue-walled bedroom, that upside-down woman, almost every day.<br><br>“Even now, I’m thinking: ‘Should I offer £500 to anyone with information on who did this?’” she says. “I need to understand. Is it personal? Is it that they hate me or is it that they hate women and don’t like to see a woman in power? Is it sectarian, because I’m a Catholic nationalist woman? Is it just that people maybe see me up there and think: ‘I’ll take her down a few pegs’?”</i> |



| Counters | Response types |
| -------- | -------------- |


DO NOT EDIT ABOVE THIS LINE - PLEASE ADD NOTES BELOW