# Technique T0166: AI-Generated Content

**Summary**: This Technique can be used to assert that a piece of content has been fully generated using AI.<br><br>This Technique’s Sub-techniques delineate specific types of AI-Generated content.<br><br>As AI continues to develop capability to produce more realistic media, it is difficult to provide a list of methods to spot materials that have been created using AI which will not rapidly become outdated; platforms providing AI media generation are attempting to make the materials they produce indistinguishable from media made by humans. <br><br>At the same time, organisations create tools designed to help identify AI-generated content, and publish resources listing the latest tells and identifiers for AI-generated content. Analysts may look for such tools or resources to help identify the use of AI.<br><br><b>Backwards Compatibility</b><br><br>In the 1.7 update to the DISARM Framework, the following Techniques were removed: <br><br>- T0085.001: Develop AI-Generated Text<br>- T0086.002: Develop AI-Generated Images (Deepfakes)<br>- T0087.001: Develop AI-Generated Videos (Deepfakes)<br>- T0088.001 Develop AI-Generated Audio (Deepfakes)<br><br>Content which has been AI-Generated can be documented using T0166: AI-Generated Content. Deepfakes can be documented using T0166.001: Deepfake Impersonation. The format of content which was edited can be documented using T0085: Develop Text-Based Content, T0086: Develop Image-Based Content, T0087: Develop Video-Based Content, and T0088: Develop Audio-Based Content.

**Tactic**: TA06 Develop Content 


| Associated Technique | Description |
| --------- | ------------------------- |
| [T0162.006 AI-Generated Content Incorrectly Presented as Depicting Reality](../../generated_pages/techniques/T0162.006.md) | T0166: AI-Generated Content which has been published alongside material which implies or directly claims that the AI-Generated Content is actually a depiction of the real world (i.e. captured by a camera, a recording device, or otherwise manually produced by a human without the use of AI) should be documented using T0162.006: AI-Generated Content Incorrectly Presented as Depicting Reality. <br><br>There are times where T0166: AI-Generated Content is published without any claim it has been produced without the use of AI, or is even disclaimed as AI, but still is mistakenly perceived as an accurate depiction of the real world (i.e. captured by a camera, a recording device, or otherwise manually produced by a human without the use of AI). Such cases can be documented using T0166: AI-Generated Content. |



| Incident | Descriptions given for this incident |
| -------- | -------------------- |
| [I00153 Fact Check: Clip of schoolchildren being instructed to chant ‘Allahu Akbar’ likely AI, experts say](../../generated_pages/incidents/I00153.md) | <i>A video shared online purporting to show a teacher in a headscarf instructing white children to bow and chant “Allahu Akbar” has probably been created using AI (T0166: AI-Generated Content), according to two AI forensics analysts who reviewed the footage for Reuters.<br><br>The 15-second clip, shared widely on social media on November 7 as if authentic, mimics CCTV footage and has a timestamp of 10:24 on November 6, 2025. It shows around a dozen uniformed pupils kneeling on prayer mats in a classroom, led by a woman, apparently a teacher, who has a British accent and is wearing a headscarf.<br><br>The children raise their hands and repeat “Allahu Akbar” (“God is Great” in Arabic) after the teacher, who then stands up and lowers herself as if sitting down, tells the children to repeat: “Subhan Allah al-A'la” (“Glory be to God the Most High” in Arabic).<br><br>One X post with 1.8 million views captioned the clip: “Young, white children are being indoctrinated into Islam. They raise their hands in the air and chant Allah Akbar. This has to stop” (T0162.006: AI-Generated Content Incorrectly Presented as Depicting Reality), while another X post viewed 1.1 million times said: “This is sick. This is the Muslim indoctrination” (T0162.006: AI-Generated Content Incorrectly Presented as Depicting Reality).<br><br>However, the two AI analysts told Reuters that visual inconsistencies that would not occur in a genuine video implied it had been created using AI (T0166: AI-Generated Content).<br><br>Siwei Lyu, a computer science professor at the University at Buffalo, United States, said via email the clip “exhibits multiple signs of AI generation”.<br><br>He said visual anomalies included the teacher sitting on an invisible chair and her face appearing distorted, the heads of students in the front row stretching unnaturally, wall decorations and texts changing over the course of the video, and a girl’s twin braids appearing and disappearing.<br><br>Rob Cover, a professor of digital communication at RMIT University in Australia, said in an email to Reuters that the clip “is very likely to have been AI-generated”.<br><br>In terms of the audio, he pointed to “metallic sounding” voices that, he said, are common for lower-quality AI-generated content and, visually, to the bodies, heads, and hair of the children being less in focus compared to their nearby surroundings.<br><br>Cover noted unusual movement in wall posters, inconsistencies in the hair tie of the girl in the front row on the far left and that the “most obvious indicator” was a missing chair when the teacher appears seated.</i> |
| [I00181 Fake academic reference reveals AI use in claim for $1.6m from NDIS](../../generated_pages/incidents/I00181.md) | <i>A behaviour support worker used artificial intelligence to create a National Disability Insurance Scheme report (T0166: AI-Generated Content) that contained fake academic references (T0163.001: Narrative Cites Nonexistent Academic Research) and data that did not exist, raising concerns about junk reports adding pressure to an already overwhelmed NDIS.<br><br>The Administrative Review Tribunal found Tenarra Campey used AI to “generate ideas” for the report for an NDIS participant, which “referenced an academic journal article that does not exist and incorrectly cited another article”.<br><br>[...]<br><br>Campey wrote on November 11, 2024, that extra support would help prevent concerning behaviour by the applicant towards his three younger siblings, a claim supported by citations to academic articles on bullying.<br><br>But at the hearing, counsel for the NDIA revealed that one of the articles, purportedly titled “Siblings, conflict and bullying” and published in the journal Developmental Review, did not exist (T0163.001: Narrative Cites Nonexistent Academic Research).<br><br>[...]<br><br>Campey expressed opinions in a letter of September 1, 2025, that she said was based on three weeks of data, but Purcell found the “data … did not exist at the time” (T0164.001: Narrative Presents Fabricated Statistics as Genuine Data) because it was collected from August 28 to September 17. </i> |
| [I00230 American Pickers' host Mike Wolfe is not in jail](../../generated_pages/incidents/I00230.md) | <i>In March and April 2025, videos surfaced on social media alleging — without any evidence to corroborate the claim — that Mike Wolfe, host of the History Channel TV show "American Pickers," had been arrested. The assertion was false (T0160.002: Information is False).<br><br>The rumor stemmed from videos uploaded by purported celebrity gossip channels on YouTube. The videos had titles like "Mike Wolfe Sentenced For Frank Frits's Death, Goodbye Forever," implying that Wolfe had been arrested (and charged, and sentenced) for the death of his former co-host, Frank Fritz. Fritz died on Sept. 30, 2024, according to an Instagram post Wolfe made the following day.<br><br>Artificial intelligence video-creation tools seemingly helped create the videos' narration, scripting, and sequencing (T0166: AI-Generated Content). Without naming an explicit source for its information, one video's narrator said:<br><br>“Mike Wolfe's sentencing stunned viewers across America when the "American Pickers" star was led away in handcuffs. Everyone thought his arrest was related to some dispute over antiques or perhaps a business disagreement with the History Channel. According to breaking news reports, Wolfe was arrested because the death of his former co-host, Frank Fritz, wasn't from natural causes as initially reported. Instead, investigators now classify it as premeditated murder. Medical reports indicate Fritz was found with lethal amounts of medication in his system. He was deliberately overdosed, and prosecutors grabbed Wolfe for the murder because it was calculated not accidental.”<br><br>That YouTube video had been viewed more than 272,000 times, as of this writing. Other YouTube videos sharing the same claim, or variations on it, also had large view counts. Posts on social media sites like Facebook also spread the supposed news.<br><br>There was no evidence to support the assertion that Wolfe had been arrested, and certainly no evidence he was arrested on charges of killing Fritz. If there was even a sliver of truth to the claim — for instance, if Wolfe had been arrested on different charges — reputable entertainment media outlets would have interviewed parties involved and documented the ordeal. That had not happened.<br><br>In short, the claim appeared to be made up from whole cloth for the purpose of gaining views online. A disclaimer at the bottom of the YouTube video read: <br><br>"Context of Information: The views and information shared in Niwra's videos are drawn from current news, reports, and personal insights. They are provided for educational and informational purposes only and may not always reflect the latest developments or offer a full perspective on the topics discussed."<br><br>Despite the fact that the video's underlying claim was false, the clip about Wolfe could seem believable because Fritz did die in September 2024, from the long-term effects of a stroke. Additionally, an unrelated Oregon man named Michael Wolfe was sentenced to life in prison in 2022 for murdering a woman and her child.<br><br>That small amount of truth inside a mountain of misleading information, combined with emotionally charged language, is a recipe that allows baseless celebrity rumors to go viral, and generate hundreds or thousands of comments from YouTube users. Some of those messages indicate that people interpret the videos to be real news.</i> |
| [I00237 Apple urged to axe AI feature after false headline](../../generated_pages/incidents/I00237.md) | <i>A major journalism body has urged Apple to scrap its new generative AI feature after it created a misleading headline about a high-profile killing in the United States.<br><br>The BBC made a complaint to the US tech giant after Apple Intelligence, which uses artificial intelligence (AI) to summarise and group together notifications, falsely created a headline about murder suspect Luigi Mangione.<br><br>The AI-powered summary falsely made it appear that BBC News had published an article claiming Mangione, the man accused of the murder of healthcare insurance CEO Brian Thompson in New York, had shot himself. He has not (T0166: AI-Generated Content, T0167.002: Title Misrepresents Content, T0160.002: Information is False, T0161.002: Statement Incorrectly Presented as Made by Individual or Institution, T0097.202: News Outlet Persona).<br><br>Now, the group Reporters Without Borders has called on Apple to remove the technology. Apple has made no comment.<br><br>Apple Intelligence was launched in the UK last week.<br><br>Reporters Without Borders, also known as RSF, said it was was "very concerned by the risks posed to media outlets" by AI tools.<br><br>The group said, external the BBC incident proves "generative AI services are still too immature to produce reliable information for the public".<br><br>Vincent Berthier, the head of RSF's technology and journalism desk, added: "AIs are probability machines, and facts can't be decided by a roll of the dice.<br><br>"RSF calls on Apple to act responsibly by removing this feature. The automated production of false information attributed to a media outlet is a blow to the outlet's credibility and a danger to the public's right to reliable information on current affairs."<br><br>[...]<br><br>The BBC does not appear to be the only news publisher which has had headlines misrepresented by Apple's new AI tech.<br><br>On 21 November, three articles from the New York Times were grouped together in one notification - with one part reading "Netanyahu arrested", referring to the Israeli prime minister.<br><br>It was inaccurately summarising a report about the International Criminal Court issuing an arrest warrant for Netanyahu, rather than any reporting about him being arrested (T0166: AI-Generated Content, T0167.002: Title Misrepresents Content, T0160.002: Information is False, T0161.002: Statement Incorrectly Presented as Made by Individual or Institution, T0097.202: News Outlet Persona).<br><br>The mistake was highlighted on Bluesky, external by journalist Ken Schwencke with the US investigative journalism website ProPublica.<br><br>Mr Schwencke told BBC News that he took the screenshot and confirmed it was real. The New York Times has declined to comment.</i> |



| Counters | Response types |
| -------- | -------------- |


DO NOT EDIT ABOVE THIS LINE - PLEASE ADD NOTES BELOW