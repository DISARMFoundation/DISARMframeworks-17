# Technique T0166.001: Deepfake Impersonation

**Summary**: This sub-technique can be used to assert that a piece of content is an AI-Generated deepfake impersonation. <br><br>A deepfake refers to AI-generated content that artificially inserts the likeness of a real person into a new or altered media scene. These synthetic images, videos, or audio clips use machine learning models to manipulate or replace the original content, making it appear as though the target is participating in actions or situations they never actually did.<br><br>As AI continues to develop capability to produce more realistic media, it is difficult to provide a list of methods to spot materials that have been created using AI which will not rapidly become outdated; platforms providing AI media generation are attempting to make the materials they produce indistinguishable from media made by humans. <br><br>At the same time, organisations create tools designed to help identify AI-generated content, and publish resources listing the latest tells and identifiers for AI-generated content. Analysts may look for such tools or resources to help identify the use of AI.

**Tactic**: TA06 Develop Content <br><br>**Parent Technique:** T0166 AI-Generated Content


| Associated Technique | Description |
| --------- | ------------------------- |



| Incident | Descriptions given for this incident |
| -------- | -------------------- |
| [I00154 UK opposition leader targeted by AI-generated fake audio smear](../../generated_pages/incidents/I00154.md) | <i>An audio clip posted to social media on Sunday, purporting to show Britain’s opposition leader Keir Starmer verbally abusing his staff, has been debunked as being AI-generated by private-sector and British government analysis (T0166.001: Deepfake Impersonation, T0097.110: Party Official Persona).<br><br>The audio of Keir Starmer was posted on X (formerly Twitter) by a pseudonymous account on Sunday morning, the opening day of the Labour Party conference in Liverpool. The account asserted that the clip, which has now been viewed more than 1.4 million times, was genuine, and that its authenticity had been corroborated by a sound engineer (T0162.006: AI-Generated Content Incorrectly Presented as Depicting Reality).<br><br>Ben Colman, the co-founder and CEO of Reality Defender — a deepfake detection business — disputed this assessment when contacted by Recorded Future News: “We found the audio to be 75% likely manipulated based on a copy of a copy that's been going around (a transcoding) (T0160.002: Information is False).<br><br>[...]<br><br>“It is also our opinion that the creator of this file added background noise to attempt evasion of detection, but our system accounts for this as well,” he said.</i> |



| Counters | Response types |
| -------- | -------------- |


DO NOT EDIT ABOVE THIS LINE - PLEASE ADD NOTES BELOW