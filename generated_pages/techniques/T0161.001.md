# Technique T0161.001: Impersonated Content

**Summary**: Content has been designed to look like it was made by another individual or institution. This has the outcome of narratives benefiting from targets’ existing faith in the impersonated entity, negatively impacting people’s faith in future content they see attributed to the impersonated entity, and tying up the impersonated entity’s resources by forcing them to spend time and effort debunking the claims attributed to them.<br><br>Common examples of impersonated content include video news reports (e.g. falsified short-form videos designed to look like they were produced by news outlets), news articles (e.g. screenshots or photographs of falsified news articles designed to look like they were published by news outlets), and documents (e.g. falsified statements designed to look like they were produced by government institutions).<br><br>Impersonated content covers direct impersonations (e.g. the use of a brand’s logo on content not produced by them), and implicit impersonations (e.g. the use of a brand’s typeface, colour scheme, formatting and style, but not naming them or using their logos). <br><br>To make this assertion, analysts may check official sources for the organisation which purportedly published the material, and look for content which was published at the date or time which the potential impersonation was published to see if it appeared on official channels. They may ask representatives from outlets to confirm whether the potential impersonation was produced by them. <br><br>They may check for inconsistencies in how content was produced (e.g. differing fonts, placement of logos, language used, use of music). They may also look for the source of materials used in the potential impersonation, which often take advantage of stock media, or splicing together footage from a variety of sources.

**Tactic**: TA06 Develop Content <br><br>**Parent Technique:** T0161 Falsified Content


| Associated Technique | Description |
| --------- | ------------------------- |
| [T0097.202 News Outlet Persona](../../generated_pages/techniques/T0097.202.md) | News Outlets are often the target of impersonated content (e.g. creating videos which falsely present themselves as having been made by a targeted news outlet). |
| [T0097.206 Government Institution Persona](../../generated_pages/techniques/T0097.206.md) | Government Institutions are often the target of impersonated content (e.g. creating documents which falsely present themselves as having been made by a targeted government institution). |
| [T0143.003 Impersonated Persona](../../generated_pages/techniques/T0143.003.md) | T0161.001: Impersonated Content differs from T0143.003: Impersonated Persona in that T0143.003: Impersonated Persona is used to document Assets which are impersonating another individual or institution (i.e. the asset is falsely presenting itself as being controlled by another entity), where T0161.001: Impersonated Content is used to document Content (i.e. Video, Audio, Text, Image) which has been produced to look like it was made by another individual or institution.<br><br>For example, a website which falsely presents itself as being controlled by an existing news outlet would be documented using T0143.003: Impersonated Persona, an article it publishes which falsely presents itself as being made by the same news outlet would be documented using T0161.001: Impersonated Content.<br><br>T0161.001: Impersonated Content does not always appear alongside T0143.003: Impersonated Persona, as T0161.001: Impersonated Content is often published by assets presenting as individuals unrelated to the impersonated individual or institution. |
| [T0161.002 Statement Incorrectly Presented as Made by Individual or Institution](../../generated_pages/techniques/T0161.002.md) | T0161.002: Statement Incorrectly Presented as Made by Individual or Institution is differentiated from T0161.001: Impersonated Content in that the former applies to claims that an individual or institution made a claim (e.g. a post which stated “The AFP made the following claim!”) where the latter applies to content intentionally produced to look like another individual or institution made it (e.g. a fake screenshot of an article published by the AFP). |
| [T0162.002 Edits Made to News Report which Reframe Context](../../generated_pages/techniques/T0162.002.md) | T0161.001: Impersonated Content documents cases where content (e.g. a news report) has been produced in the style of a third party, falsely attributing newly created content to that organisation. T0162.002: Edits Made to News Report which Reframe Context documents cases where existing news reports have been edited to introduce new meaning (e.g. new voiceovers, new clips). There are cases where T0161.001: Impersonated Content takes clips from existing news reports to facilitate the production of the impersonation, in which case both T0161.001: Impersonated Content and T0162.002: Edits Made to News Report which Reframe Context can be used. |
| [T0162.006 AI-Generated Content Incorrectly Presented as Depicting Reality](../../generated_pages/techniques/T0162.006.md) | T0166.001: Deepfake Impersonation which has been published alongside material which implies or directly claims that the T0166.001: Deepfake Impersonation is actually a depiction of the real world (i.e. captured by a camera, a recording device, or otherwise manually produced by a human without the use of AI) should be documented using T0162.006: AI-Generated Content Incorrectly Presented as Depicting Reality.  |
| [T0166.002 Sexual Deepfake Impersonation](../../generated_pages/techniques/T0166.002.md) | T0166.001: Deepfake Impersonation which is sexual in nature should be documented using T0166.002: Sexual Deepfake Impersonation. The nature of what is considered sexual can differ based on cultural context. Analysts will need to consider the societal norms of the targeted individual, or the audience of the deepfake when asserting whether it is sexual in nature. |



| Incident | Descriptions given for this incident |
| -------- | -------------------- |
| [I00210 False: An Italian news channel used visuals from the film Deep Impact to depict an exodus of people from Kyiv.](../../generated_pages/incidents/I00210.md) | <i>Since Russia invaded Ukraine, misinformation relating to the conflict has spread. A recent tweet claimed that media outlets were using clips from the movie Deep Impact to report the war. The tweet compared two similar images which show people running on a highway packed with cars. One image had text which said Deep Impact, and the other with the logo of TGcom24, an Italian news channel, with the text "Escape from Kiev."<br><br>After analyzing TGcom24's reports of Ukraine and Russia, it is clear that the news channel did not use footage from the movie. After comparing the image from the tweet with video footage from TGcom24, Logically found that the image is altered. The logo in the tweet is hazy and pixelated. The logo's format and placement were also different in the tweet. Official footage from TGcom24 shows their logo usually on the bottom right of the screen and not on the top right (T0161.001: Impersonated Content, T0097.202: News Outlet Persona).<br><br>We could not find where this edited image first appeared through a reverse image search. Most results showed stock images from the movie. The Twitter post in question was made on June 19, 2022. TGcom24 has never published any reports using the image in question.<br><br>The image in the tweet has been digitally altered to appear as though TGcom24 used a still from the film Deep Impact. There are no reports from the Italian news outlet that includes this image. Hence we have marked this claim as false (T0160.002: Information is False).</i> |
| [I00213 No, USAID didn't pay Hollywood actors millions to visit Ukraine | Fact check](../../generated_pages/incidents/I00213.md) | <i>A Feb. 5 Facebook post shows what appears to be a news report from E! News claiming the U.S. Agency for International Development paid Hollywood actors to visit Ukraine.<br><br>"USAID sponsored American celebrity visits to Ukraine after Russia's full-scale invasion began," reads text on the video, which is accompanied by a voiceover narration. "Angelina Jolie, $20,000,000. Sean Penn, $5,000,000. Jean-Claude Van Damm (sic), $1,500,000. Orlando Bloom, $8,000,000. Ben Stiller, $4,000,000."<br><br>The video uses the E! News logo throughout.<br><br>The Facebook post was shared more than 300 times in five days. The video was also spread by Donald Trump Jr. on X.<br><br>The video is a fabrication that wasn't reported or published by E! News, a company spokesperson said (T0161.001: Impersonated Content). The video is consistent with material created by a Russia-aligned influence campaign, disinformation experts said.<br><br>President John F. Kennedy created USAID by executive order after signing the Foreign Assistance Act in 1961. The global aid agency has been targeted for apparent dismantling by billionaire Elon Musk (T0068: Respond to Breaking News Event or Active Crisis), the head of President Donald Trump's Department of Government Efficiency. Trump told reporters he loved "the concept" of USAID but claimed the agency "turned out to be radical left lunatics."<br><br>The video in the Facebook post plays into the scrutiny of the agency by linking USAID to Hollywood celebrities and U.S. support for Ukraine. But the video is not a real news report from E! News. It's a fabrication that deceptively uses the branding of the entertainment news outlet to spread a false narrative (T0160.002: Information is False).<br><br>An E! News spokesperson who declined to provide a name for attribution said the video is not authentic and not from E! News.<br><br>Multiple actors mentioned in the video also said the claims USAID paid them to visit Ukraine were false. Bloom said in an Instagram post that such reports were "untrue." Stiller wrote in an X post that his trip to Ukraine was "completely self-funded." Mathew Rosengart, Penn's longtime lawyer, similarly said in an email that Penn's travel to Ukraine was "self-funded" and not sponsored by USAID. A spokesperson for Angelina Jolie, who declined to be identified, also told USA TODAY the payment claim was wrong and Jolie has personally covered the cost for all her humanitarian missions.<br><br>Patrick Warren, co-director of the Media Forensics Hub at Clemson University and researcher of online disinformation, said he's "confident" the video traces back to Russia because it has indicators consistent with the ongoing Russia-aligned Matryoshka influence campaign, including the mimicking of an authentic news outlet, the use of an AI voiceover (T0166: AI-Generated Content) and the targeting of Ukraine.<br><br>This type of Russian malign influence commonly takes advantage of "current news – like U.S. AID – to insert anti-Ukraine messaging into the discourse," Warren said in an email. He added the video in the Facebook post was first shared on X by an account that "regularly initiates" narratives propagated by the Kremlin-aligned Storm-1516 influence network. The narrative in the fabricated video appeared on Russian state media around the same time the X post was shared and appeared on pro-Russian Telegram channels, Warren said.<br><br>Darren Linvill, another co-director of Clemson's Media Forensics Hub, noted in an X thread that Musk and Trump Jr. amplified the video and that it had "every indication of being a Russian-fabricated video" that never appeared on E! News. Attempts to reach Musk and Trump Jr. for comment were not immediately successful.<br><br>USA TODAY reached out to the Facebook user who shared the post for comment but did not immediately receive a response. Attempts to reach Van Damme for comment were also unsuccessful.<br><br>§</i> |



| Counters | Response types |
| -------- | -------------- |


DO NOT EDIT ABOVE THIS LINE - PLEASE ADD NOTES BELOW